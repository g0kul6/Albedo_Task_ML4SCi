{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the path to the folder \n",
    "dir=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to data\n",
    "mercury_albedo_top=dir+\"/DATA/Data_Mercury/mercury-albedo-top-half.png.csv\"\n",
    "mercury_albedo_bottom=dir+\"/DATA/Data_Mercury/mercury-albedo-resized-bottom-half.png.csv\"\n",
    "alsi_map=dir+\"/DATA/Data_Mercury/alsimap_smooth_032015.png.csv\"\n",
    "casi_map=dir+\"/DATA/Data_Mercury/casimap_smooth_032015.png.csv\"\n",
    "fesi_map=dir+\"/DATA/Data_Mercury/fesimap_smooth_032015.png.csv\"\n",
    "mgsi_map=dir+\"/DATA/Data_Mercury/mgsimap_smooth_032015.png.csv\"\n",
    "ssi_map=dir+\"/DATA/Data_Mercury/ssimap_smooth_032015.png.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1438, 1440)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "che=cv2.resize(np.array(pd.read_csv(alsi_map)),(1440,1438))\n",
    "che1=cv2.resize(np.array(pd.read_csv(casi_map)),(1440,1438))\n",
    "che2=cv2.resize(np.array(pd.read_csv(fesi_map)),(1440,1438))\n",
    "che3=cv2.resize(np.array(pd.read_csv(mgsi_map)),(1440,1438))\n",
    "che4=cv2.resize(np.array(pd.read_csv(ssi_map)),(1440,1438))\n",
    "img=np.concatenate([np.array(pd.read_csv(mercury_albedo_top)).flatten(),np.array(pd.read_csv(mercury_albedo_bottom)).flatten()]).reshape((1438,1440))\n",
    "dummy=che+che1+che2+che3+che4\n",
    "print(np.shape(dummy))\n",
    "for i in range(np.shape(dummy)[0]):\n",
    "    for j in range(np.shape(dummy)[1]):\n",
    "        if che[i][j]==0 or che1[i][j]==0 or che2[i][j]==0 or che3[i][j]==0 or che4[i][j]==0:\n",
    "            img[i][j]=0\n",
    "\n",
    "# plt.imshow(img[:719,:])\n",
    "plt.hist(img[:,719:].flatten(),bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_nearby_pixel(Dataset):\n",
    "    def __init__(self,path_1,path_2,path_3,path_4,path_5,path_6,mode):\n",
    "        self.path_1=path_1\n",
    "        self.path_2=path_2\n",
    "        self.path_3=path_3\n",
    "        self.path_4=path_4\n",
    "        self.path_5=path_5\n",
    "        self.path_6=path_6\n",
    "        self.mode=mode\n",
    "        #converting the data to ndarray\n",
    "        if mode == \"Train\" or \"train\":\n",
    "            self.X_1=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_1)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_2=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_2)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_3=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_3)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_4=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_4)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_5=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_5)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "        elif mode == \"Test\" or \"test\":\n",
    "            self.X_1=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_1)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_2=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_2)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_3=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_3)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_4=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_4)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_5=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_5)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "        self.X_6=np.array(pd.read_csv(path_6))\n",
    "        self.X=[]\n",
    "        self.Y=[]\n",
    "        n,m=np.shape(self.X_6)[0],np.shape(self.X_6)[1]\n",
    "        #mask\n",
    "        # for l in range(n):\n",
    "        #     for b in range(m):\n",
    "        #         if self.X_1[l][b]==0 or self.X_2[l][b]==0 or self.X_3[l][b]==0 or self.X_4[l][b]==0 or self.X_5[l][b]==0:\n",
    "        #             self.X_6[l][b]=0\n",
    "        for i in range(1,n-1):\n",
    "            for j in range(1,m-1):\n",
    "                nearby=[]\n",
    "                for a in [-1,0,1]:\n",
    "                    for b in [-1,0,1]:\n",
    "                        nearby.append(self.X_6[i+a][j+b])\n",
    "                # if sum(nearby) !=0 and sum([self.X_1[i][j],self.X_2[i][j],self.X_3[i][j],self.X_4[i][j],self.X_5[i][j]])!=0:\n",
    "                self.X.append(nearby)\n",
    "                self.Y.append([self.X_1[i][j],self.X_2[i][j],self.X_3[i][j],self.X_4[i][j],self.X_5[i][j]])\n",
    "        self.X=np.array(self.X)\n",
    "        self.Y=np.array(self.Y)\n",
    "    def __len__(self):\n",
    "        self.filelength=np.shape(self.Y)[0]\n",
    "        return self.filelength\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.from_numpy(self.X[idx]),torch.from_numpy(self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_normal(Dataset):\n",
    "    def __init__(self,path_1,path_2,path_3,path_4,path_5,path_6,mode):\n",
    "        self.path_1=path_1\n",
    "        self.path_2=path_2\n",
    "        self.path_3=path_3\n",
    "        self.path_4=path_4\n",
    "        self.path_5=path_5\n",
    "        self.path_6=path_6\n",
    "        self.mode=mode\n",
    "        #converting the data to ndarray\n",
    "        if mode == \"Train\" or \"train\":\n",
    "            self.X_1=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_1)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_2=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_2)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_3=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_3)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_4=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_4)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_5=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_5)),(1440,1438))[:719,:],ksize=(0,0),sigmaX=9)\n",
    "        elif mode == \"Test\" or \"test\":\n",
    "            self.X_1=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_1)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_2=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_2)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_3=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_3)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_4=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_4)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "            self.X_5=cv2.GaussianBlur(cv2.resize(np.array(pd.read_csv(path_5)),(1440,1438))[719:,:],ksize=(0,0),sigmaX=9)\n",
    "        self.X_6=np.array(pd.read_csv(path_6))\n",
    "        self.X=np.array(self.X_6.flatten())\n",
    "        self.Y=np.stack((self.X_1.flatten(),self.X_2.flatten(),self.X_3.flatten(),self.X_4.flatten(),self.X_5.flatten()),1)  \n",
    "    def __len__(self):\n",
    "        self.filelength=np.shape(self.Y)[0]\n",
    "        return self.filelength\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.tensor(self.X[idx]),torch.from_numpy(self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(model, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature, n_hidden)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden,n_hidden)\n",
    "        self.hidden3 = torch.nn.Linear(n_hidden,n_hidden)\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.hidden1(x)))\n",
    "        x = self.dropout(F.relu(self.hidden2(x)))\n",
    "        x = self.dropout(F.relu(self.hidden3(x)))\n",
    "        x = self.predict(x)            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        # Encoder Network\n",
    "        self.encoder = torch.nn.Sequential(torch.nn.Linear(9,18),\n",
    "                                     torch.nn.ReLU(True),\n",
    "                                     torch.nn.Linear(18,36),\n",
    "                                     torch.nn.ReLU(True),\n",
    "                                     torch.nn.Linear(36,72))\n",
    "\n",
    "        # Decoder Network\n",
    "        self.decoder = torch.nn.Sequential(torch.nn.Linear(72,36),\n",
    "                                     torch.nn.ReLU(True),\n",
    "                                     torch.nn.Linear(36,18),\n",
    "                                     torch.nn.ReLU(True),\n",
    "                                     torch.nn.Linear(18,9),\n",
    "                                     torch.nn.ReLU(True),\n",
    "                                     torch.nn.Linear(9,5),\n",
    "                                     torch.nn.ReLU(True))\n",
    "    def forward(self,x):\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train():\n",
    "    def __init__(self,batch_size,epochs,lr,train_val_split,scheduler,net_type,type):\n",
    "        self.batch_size=batch_size\n",
    "        self.scheduler=scheduler\n",
    "        self.epochs=epochs\n",
    "        self.lr=lr\n",
    "        self.train_val_split=train_val_split\n",
    "        self.net_type=net_type\n",
    "        self.type=type\n",
    "        if self.type==\"nearby\":\n",
    "            self.data=dataset_nearby_pixel(alsi_map,casi_map,fesi_map,mgsi_map,ssi_map,mercury_albedo_top,mode=\"Train\")\n",
    "            if net_type==\"normal\":\n",
    "                self.net=model(n_feature=9, n_hidden=11, n_output=5)\n",
    "            elif net_type==\"autoencoder\":\n",
    "                self.net=autoencoder()\n",
    "        elif self.type==\"normal\":\n",
    "            self.data=dataset_normal(alsi_map,casi_map,fesi_map,mgsi_map,ssi_map,mercury_albedo_top,mode=\"Train\")\n",
    "            if net_type==\"normal\":\n",
    "                self.net=model(n_feature=1, n_hidden=16, n_output=5)\n",
    "        self.train_data,self.val_data=random_split(self.data,[len(self.data)-int(self.train_val_split*len(self.data)),int(self.train_val_split*len(self.data))],generator=torch.Generator().manual_seed(42))\n",
    "        self.train_loader=DataLoader(self.train_data,batch_size=self.batch_size,shuffle=True)\n",
    "        self.val_loader=DataLoader(self.val_data,batch_size=self.batch_size,shuffle=True)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        if self.scheduler==True:\n",
    "            self.sched=torch.optim.lr_scheduler.ExponentialLR(self.optimizer,gamma=0.7)\n",
    "        self.loss_func = torch.nn.MSELoss() \n",
    "        self.writer = SummaryWriter()\n",
    "        \n",
    "    def trainer(self):\n",
    "        self.net=self.net.train()\n",
    "        self.net=self.net.cuda()\n",
    "        for epoch in range(self.epochs):\n",
    "            for input,gt in self.train_loader:\n",
    "                input = input.cuda()\n",
    "                gt = gt.cuda()\n",
    "                input=torch.reshape(input,(len(input),1))\n",
    "                output = self.net(input.float())\n",
    "                loss = self.loss_func(output, gt.float())\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            if self.scheduler == True:\n",
    "                self.sched.step()\n",
    "            print('Epoch : {},  train loss : {}'.format(epoch+1,loss.item()))\n",
    "            with torch.no_grad():\n",
    "                for input,gt in self.val_loader:\n",
    "                    input=input.cuda()\n",
    "                    gt= gt.cuda()\n",
    "                    input=torch.reshape(input,(len(input),1))\n",
    "                    val_output = self.net(input.float())\n",
    "                    val_loss = self.loss_func(val_output,gt.float())\n",
    "            print('Epoch : {},  val_loss : {}'.format(epoch+1,val_loss.item()))\n",
    "            self.writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            self.writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "            if self.scheduler == True:\n",
    "                self.writer.add_scalar(\"lr/epoch\",self.lr,epoch)\n",
    "        torch.save(self.net.state_dict(),f\"albedo_{self.epochs}_{self.lr}_{self.batch_size}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1,  train loss : 0.03133977949619293\n",
      "Epoch : 1,  val_loss : 0.03870938718318939\n",
      "Epoch : 2,  train loss : 0.05512449890375137\n",
      "Epoch : 2,  val_loss : 0.05250141769647598\n",
      "Epoch : 3,  train loss : 0.051994312554597855\n",
      "Epoch : 3,  val_loss : 0.043464284390211105\n",
      "Epoch : 4,  train loss : 0.05054280906915665\n",
      "Epoch : 4,  val_loss : 0.055228590965270996\n",
      "Epoch : 5,  train loss : 0.0480491928756237\n",
      "Epoch : 5,  val_loss : 0.049581825733184814\n",
      "Epoch : 6,  train loss : 0.040794581174850464\n",
      "Epoch : 6,  val_loss : 0.07783304899930954\n",
      "Epoch : 7,  train loss : 0.04052238538861275\n",
      "Epoch : 7,  val_loss : 0.06566587835550308\n",
      "Epoch : 8,  train loss : 0.04446837306022644\n",
      "Epoch : 8,  val_loss : 0.07925110310316086\n",
      "Epoch : 9,  train loss : 0.08344703167676926\n",
      "Epoch : 9,  val_loss : 0.04153115674853325\n",
      "Epoch : 10,  train loss : 0.049902305006980896\n",
      "Epoch : 10,  val_loss : 0.04501420632004738\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000008?line=0'>1</a>\u001b[0m train_best_near\u001b[39m=\u001b[39mtrain(batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,lr\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,train_val_split\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m,scheduler\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,net_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000008?line=1'>2</a>\u001b[0m train_best_near\u001b[39m.\u001b[39;49mtrainer()\n",
      "\u001b[1;32m/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain.trainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000007?line=37'>38</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_func(output, gt\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000007?line=38'>39</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000007?line=39'>40</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000007?line=40'>41</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/g0kul6/g0kul6/ml4sci/MLMAPPER/mercury_albedo.ipynb#ch0000007?line=41'>42</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=235'>236</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=236'>237</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=237'>238</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=238'>239</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=242'>243</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=243'>244</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/tensor.py?line=244'>245</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py?line=141'>142</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py?line=142'>143</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py?line=144'>145</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py?line=145'>146</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///home/g0kul6/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py?line=146'>147</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_best_near=train(batch_size=64,epochs=100,lr=0.0001,train_val_split=0.3,scheduler=False,net_type=\"normal\",type=\"normal\")\n",
    "train_best_near.trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9ebc0819e6879c9252ac39d1ed70d90cf78c6e7bbaabf45459c0f34b6327c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
