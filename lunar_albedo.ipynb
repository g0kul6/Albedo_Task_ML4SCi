{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLMAPPER USING NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to data \n",
    "albedo=\"/home/gokul/g0kul6/ml4sci/Data_Albedo/Albedo_Map.csv\"\n",
    "LPFe_Map=\"/home/gokul/g0kul6/ml4sci/Data_Albedo/LPFe_Map.csv\"\n",
    "LPK_Map=\"/home/gokul/g0kul6/ml4sci/Data_Albedo/LPK_Map.csv\"\n",
    "LPTh_Map=\"/home/gokul/g0kul6/ml4sci/Data_Albedo/LPTh_Map.csv\"\n",
    "LPTi_Map=\"/home/gokul/g0kul6/ml4sci/Data_Albedo/LPTi_Map.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOM DATASET TO GET INPUT,GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataset\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,path_1,path_2,path_3,path_4,path_5,start_split,end_split):\n",
    "    self.path_1=path_1\n",
    "    self.path_2=path_2\n",
    "    self.path_3=path_3\n",
    "    self.path_4=path_4\n",
    "    self.path_5=path_5\n",
    "    self.start_split=start_split\n",
    "    self.end_split=end_split\n",
    "    self.X_1=torch.FloatTensor(np.array(pd.read_csv(path_1)))\n",
    "    self.X_2=torch.FloatTensor(np.array(pd.read_csv(path_2)))\n",
    "    self.X_3=torch.FloatTensor(np.array(pd.read_csv(path_3)))\n",
    "    self.X_4=torch.FloatTensor(np.array(pd.read_csv(path_4)))\n",
    "    self.X_5=torch.FloatTensor(np.array(pd.read_csv(path_5)))\n",
    "    self.X_1=(self.X_1[:,self.start_split:self.end_split].flatten()-torch.mean(self.X_1[:,self.start_split:self.end_split].flatten()))/torch.std(self.X_1[:,self.start_split:self.end_split].flatten())\n",
    "    self.X_2=(self.X_2[:,self.start_split:self.end_split].flatten()-torch.mean(self.X_2[:,self.start_split:self.end_split].flatten()))/torch.std(self.X_2[:,self.start_split:self.end_split].flatten())\n",
    "    self.X_3=(self.X_3[:,self.start_split:self.end_split].flatten()-torch.mean(self.X_3[:,self.start_split:self.end_split].flatten()))/torch.std(self.X_3[:,self.start_split:self.end_split].flatten())\n",
    "    self.X_4=(self.X_4[:,self.start_split:self.end_split].flatten()-torch.mean(self.X_4[:,self.start_split:self.end_split].flatten()))/torch.std(self.X_4[:,self.start_split:self.end_split].flatten())\n",
    "    self.X_5=self.X_5[:,self.start_split:self.end_split].flatten()\n",
    "    self.X=torch.stack((self.X_1,self.X_2,self.X_3,self.X_4),1)  \n",
    "    self.Y=self.X_5\n",
    "  \n",
    "  def __len__(self):\n",
    "    self.filelength=len(self.Y)\n",
    "    return self.filelength\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx],self.Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network model\n",
    "class model(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(model, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature, n_hidden)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden,n_hidden)\n",
    "        self.hidden3 = torch.nn.Linear(n_hidden,n_hidden)    \n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.hidden1(x)))\n",
    "        x = self.dropout(F.relu(self.hidden2(x)))\n",
    "        x = self.dropout(F.relu(self.hidden3(x)))      \n",
    "        x = self.predict(x)            \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train():\n",
    "    def __init__(self,batch_size,epochs,lr,train_val_split):\n",
    "        self.batch_size=batch_size\n",
    "        self.epochs=epochs\n",
    "        self.lr=lr\n",
    "        self.train_val_split=train_val_split\n",
    "        self.data=dataset(LPFe_Map,LPK_Map,LPTh_Map,LPTi_Map,albedo,0,360)\n",
    "        self.train_data,self.val_data=random_split(self.data,[len(self.data)-int(self.train_val_split*len(self.data)),int(self.train_val_split*len(self.data))],generator=torch.Generator().manual_seed(42))\n",
    "        self.train_loader=DataLoader(self.train_data,batch_size=self.batch_size,shuffle=True)\n",
    "        self.val_loader=DataLoader(self.val_data,batch_size=self.batch_size,shuffle=True)\n",
    "        self.net=model(n_feature=4, n_hidden=10, n_output=1)  \n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        #self.scheduler=torch.optim.lr_scheduler.ExponentialLR(self.optimizer,gamma=0.9)\n",
    "        self.loss_func = torch.nn.MSELoss() \n",
    "        self.writer = SummaryWriter()\n",
    "    def trainer(self):\n",
    "        self.net=self.net.train()\n",
    "        self.net=self.net.cuda()\n",
    "        for epoch in range(self.epochs):\n",
    "            for input,gt in self.train_loader:\n",
    "                input = input.cuda()\n",
    "                gt = gt.cuda()\n",
    "                gt=torch.reshape(gt,(len(gt),1))\n",
    "                output = self.net(input)\n",
    "                loss = self.loss_func(output, gt)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            #self.scheduler.step()\n",
    "            print('Epoch : {},  train loss : {}'.format(epoch+1,loss.item()))\n",
    "            with torch.no_grad():\n",
    "                for input,gt in self.val_loader:\n",
    "                    input=input.cuda()\n",
    "                    gt= gt.cuda()\n",
    "                    gt=torch.reshape(gt,(len(gt),1))\n",
    "                    val_output = self.net(input)\n",
    "                    val_loss = self.loss_func(val_output,gt)\n",
    "            print('Epoch : {},  val_loss : {}'.format(epoch+1,val_loss.item()))\n",
    "            self.writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            self.writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        torch.save(self.net.state_dict(),f\"albedo_{self.epochs}_{self.lr}.pth\")\n",
    "train_1=train(batch_size=128,epochs=200,lr=0.00001,train_val_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the model:\n",
    "#### Model that I am using is a neural network with 3-hidden layers,activation function as RELU and dropout with p=0.2\n",
    "#### Loss function = Mean Squared Error Loss(MSE)\n",
    "#### Optimizer     = Adam \n",
    "#### After a lot of hyper-parameter tuning the model showed convergance and better results for lr=0.00001,batchsize=128,train-validatio=70-30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Loss on right half : 0.026970662753440646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 0.000e+00, 3.000e+00,\n",
       "        7.000e+00, 6.000e+00, 1.000e+01, 6.000e+00, 1.300e+01, 1.800e+01,\n",
       "        2.900e+01, 3.200e+01, 3.600e+01, 4.800e+01, 7.200e+01, 8.800e+01,\n",
       "        9.300e+01, 1.610e+02, 2.020e+02, 3.040e+02, 3.900e+02, 4.460e+02,\n",
       "        5.560e+02, 7.290e+02, 8.800e+02, 1.126e+03, 1.309e+03, 1.619e+03,\n",
       "        1.950e+03, 2.356e+03, 2.722e+03, 3.239e+03, 3.697e+03, 4.261e+03,\n",
       "        4.659e+03, 5.154e+03, 5.826e+03, 6.298e+03, 6.789e+03, 7.117e+03,\n",
       "        7.307e+03, 7.312e+03, 7.213e+03, 6.975e+03, 6.409e+03, 5.769e+03,\n",
       "        5.003e+03, 4.313e+03, 3.559e+03, 3.000e+03, 2.400e+03, 1.875e+03,\n",
       "        1.521e+03, 1.178e+03, 8.290e+02, 5.840e+02, 4.390e+02, 3.350e+02,\n",
       "        2.450e+02, 1.690e+02, 1.150e+02, 9.500e+01, 7.000e+01, 5.100e+01,\n",
       "        4.100e+01, 3.600e+01, 2.600e+01, 1.900e+01, 1.700e+01, 1.700e+01,\n",
       "        1.000e+01, 1.000e+01, 4.000e+00, 5.000e+00, 6.000e+00, 6.000e+00,\n",
       "        5.000e+00, 3.000e+00, 3.000e+00, 3.000e+00, 1.000e+00, 1.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([-0.21495596, -0.21077755, -0.20659915, -0.20242074, -0.19824233,\n",
       "        -0.19406393, -0.18988552, -0.18570712, -0.18152871, -0.1773503 ,\n",
       "        -0.1731719 , -0.16899349, -0.16481509, -0.16063668, -0.15645827,\n",
       "        -0.15227987, -0.14810146, -0.14392306, -0.13974465, -0.13556624,\n",
       "        -0.13138784, -0.12720943, -0.12303103, -0.11885262, -0.11467421,\n",
       "        -0.11049581, -0.1063174 , -0.102139  , -0.09796059, -0.09378218,\n",
       "        -0.08960378, -0.08542537, -0.08124697, -0.07706856, -0.07289015,\n",
       "        -0.06871175, -0.06453334, -0.06035494, -0.05617653, -0.05199812,\n",
       "        -0.04781972, -0.04364131, -0.03946291, -0.0352845 , -0.03110609,\n",
       "        -0.02692769, -0.02274928, -0.01857088, -0.01439247, -0.01021406,\n",
       "        -0.00603566, -0.00185725,  0.00232115,  0.00649956,  0.01067797,\n",
       "         0.01485637,  0.01903478,  0.02321318,  0.02739159,  0.03157   ,\n",
       "         0.0357484 ,  0.03992681,  0.04410521,  0.04828362,  0.05246203,\n",
       "         0.05664043,  0.06081884,  0.06499724,  0.06917565,  0.07335406,\n",
       "         0.07753246,  0.08171087,  0.08588928,  0.09006768,  0.09424609,\n",
       "         0.09842449,  0.1026029 ,  0.10678131,  0.11095971,  0.11513812,\n",
       "         0.11931652,  0.12349493,  0.12767334,  0.13185174,  0.13603015,\n",
       "         0.14020855,  0.14438696,  0.14856537,  0.15274377,  0.15692218,\n",
       "         0.16110058,  0.16527899,  0.1694574 ,  0.1736358 ,  0.17781421,\n",
       "         0.18199261,  0.18617102,  0.19034943,  0.19452783,  0.19870624,\n",
       "         0.20288464]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATXklEQVR4nO3df4xc13mf8ecb2lbVpISlaMWw/FEqKJGEEmI5WrAsHLRNlFR0HIT6RwGDNCIKAmwENlaAFAXZAC2KgoAKFEEjICJKyK5I1DFDJDZEpFZclY0RBKEtrxzXCkUroi1FWpAhGcWumQZgTPbtH3tkDZbD3VlqObvL83yAi7nzzj0zZy52v3v2zL13UlVIkvrwXUvdAUnS+Bj6ktQRQ1+SOmLoS1JHDH1J6sh7lroD87nrrrtq06ZNS90NSVpRXnzxxb+oqonZ9WUf+ps2bWJqamqpuyFJK0qSPxtWd3pHkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6suzPyJWW2qZ9/31o/fUnPjLmnkjvniN9SeqIoS9JHXF6R7pBg9M+TvVopXCkL0kdmXekn+QHgN8aKH0/8G+BI62+CXgd+Nmq+kZrsx/YDVwFPlpVn231B4BngNuBzwCPV1UtzluRFs/1PryVVrp5R/pV9UpV3V9V9wMPAH8NfBrYB5yoqs3AiXafJFuAncC9wHbgqSSr2tMdBPYAm9uyfVHfjSRpTgud3nkQ+FpV/RmwAzjc6oeBh9v6DuBoVV2uqteAM8DWJGuB1VV1so3ujwy0kSSNwUJDfyfwyba+pqrOAbTbu1t9HfDmQJvpVlvX1mfXJUljMvLRO0neB/wMsH++TYfUao76sNfaw8w0EBs3bhy1i9KS8UgerRQLGel/GPhSVZ1v98+3KRva7YVWnwY2DLRbD5xt9fVD6teoqkNVNVlVkxMT13yvryTpBi0k9H+Od6Z2AI4Du9r6LuDZgfrOJLcluYeZD2xfaFNAl5JsSxLg0YE2kqQxGGl6J8nfBn4S+BcD5SeAY0l2A28AjwBU1akkx4CXgSvA3qq62to8xjuHbD7XFknSmIwU+lX118D3zqq9xczRPMO2PwAcGFKfAu5beDclSYvBM3IlqSNee0dqPAtXPXCkL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHfGMXGmReW19LWeO9CWpI4a+JHXE6R11zYusqTeO9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjJS6Cd5f5LfTvLVJKeT/MMkdyZ5Psmr7faOge33JzmT5JUkDw3UH0jyUnvsySS5GW9KkjTcqCP9Xwd+r6p+EPgAcBrYB5yoqs3AiXafJFuAncC9wHbgqSSr2vMcBPYAm9uyfZHehyRpBPOGfpLVwD8CPgZQVX9TVd8EdgCH22aHgYfb+g7gaFVdrqrXgDPA1iRrgdVVdbKqCjgy0EaSNAajjPS/H7gI/Nckf5zk6STfDaypqnMA7fbutv064M2B9tOttq6tz65fI8meJFNJpi5evLigNyRJur5RQv89wI8AB6vqg8D/pU3lXMewefqao35tsepQVU1W1eTExMQIXZQkjWKU0J8GpqvqC+3+bzPzR+B8m7Kh3V4Y2H7DQPv1wNlWXz+kLkkak3lDv6r+HHgzyQ+00oPAy8BxYFer7QKebevHgZ1JbktyDzMf2L7QpoAuJdnWjtp5dKCNJGkMRr3g2i8Bn0jyPuDrwD9n5g/GsSS7gTeARwCq6lSSY8z8YbgC7K2qq+15HgOeAW4HnmuLJGlMRgr9qvoyMDnkoQevs/0B4MCQ+hRw3wL6Jy06r6ypnnlpZekm8lu0tNx4GQZJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiN+cpS74FYnSjJFG+kleT/JSki8nmWq1O5M8n+TVdnvHwPb7k5xJ8kqShwbqD7TnOZPkySRZ/LckSbqehUzv/FhV3V9Vb39B+j7gRFVtBk60+yTZAuwE7gW2A08lWdXaHAT2AJvbsv3dvwVJ0qjezZz+DuBwWz8MPDxQP1pVl6vqNeAMsDXJWmB1VZ2sqgKODLSRJI3BqHP6BfyPJAX8l6o6BKypqnMAVXUuyd1t23XA5wfaTrfat9v67Po1kuxh5j8CNm7cOGIXpeVt8HOF15/4yBL2RD0bNfQ/VFVnW7A/n+Src2w7bJ6+5qhfW5z5o3IIYHJycug2kqSFG2l6p6rOttsLwKeBrcD5NmVDu73QNp8GNgw0Xw+cbfX1Q+qSpDGZN/STfHeSv/P2OvBPgT8BjgO72ma7gGfb+nFgZ5LbktzDzAe2L7SpoEtJtrWjdh4daCNJGoNRpnfWAJ9uR1e+B/jNqvq9JF8EjiXZDbwBPAJQVaeSHANeBq4Ae6vqanuux4BngNuB59oiSRqTeUO/qr4OfGBI/S3gweu0OQAcGFKfAu5beDclSYvByzBIUkcMfUnqiKEvSR0x9CWpI15lU7csr6wpXcuRviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcQzcqUl4PflaqkY+rqleOkFaW5O70hSRwx9SeqIoS9JHRk59JOsSvLHSX633b8zyfNJXm23dwxsuz/JmSSvJHlooP5AkpfaY0+mfdu6JGk8FjLSfxw4PXB/H3CiqjYDJ9p9kmwBdgL3AtuBp5Ksam0OAnuAzW3Z/q56L0lakJFCP8l64CPA0wPlHcDhtn4YeHigfrSqLlfVa8AZYGuStcDqqjpZVQUcGWgjSRqDUUf6/xn418D/G6itqapzAO327lZfB7w5sN10q61r67PrkqQxmTf0k/w0cKGqXhzxOYfN09cc9WGvuSfJVJKpixcvjviykqT5jDLS/xDwM0leB44CP57kvwHn25QN7fZC234a2DDQfj1wttXXD6lfo6oOVdVkVU1OTEws4O1IkuYyb+hX1f6qWl9Vm5j5gPZ/VdU/A44Du9pmu4Bn2/pxYGeS25Lcw8wHti+0KaBLSba1o3YeHWgjSRqDd3MZhieAY0l2A28AjwBU1akkx4CXgSvA3qq62to8BjwD3A481xZJ0pgsKPSr6nPA59r6W8CD19nuAHBgSH0KuG+hnZQkLQ7PyJWkjhj6ktQRQ1+SOuL19LXieQ19aXSO9CWpI4a+JHXE0JekjjinLy0xvyRd4+RIX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRT87SiuRF1qQb40hfkjpi6EtSRwx9SerIvKGf5G8leSHJ/05yKsm/b/U7kzyf5NV2e8dAm/1JziR5JclDA/UHkrzUHnsySW7O25IkDTPKSP8y8ONV9QHgfmB7km3APuBEVW0GTrT7JNkC7ATuBbYDTyVZ1Z7rILAH2NyW7Yv3ViRJ85k39GvGX7W7721LATuAw61+GHi4re8AjlbV5ap6DTgDbE2yFlhdVSerqoAjA20kSWMw0iGbbaT+IvD3gd+oqi8kWVNV5wCq6lySu9vm64DPDzSfbrVvt/XZ9WGvt4eZ/wjYuHHj6O9GWuG8tr5utpE+yK2qq1V1P7CemVH7fXNsPmyevuaoD3u9Q1U1WVWTExMTo3RRkjSCBR29U1XfBD7HzFz8+TZlQ7u90DabBjYMNFsPnG319UPqkqQxGeXonYkk72/rtwM/AXwVOA7sapvtAp5t68eBnUluS3IPMx/YvtCmgi4l2daO2nl0oI0kaQxGmdNfCxxu8/rfBRyrqt9NchI4lmQ38AbwCEBVnUpyDHgZuALsraqr7bkeA54Bbgeea4skaUzmDf2q+grwwSH1t4AHr9PmAHBgSH0KmOvzAEnSTeQZuZLUEUNfkjripZW1Yng5Zendc6QvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6ognZ0nLlF+oopvB0Ney5lm40uJyekeSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZN7QT7Ihye8nOZ3kVJLHW/3OJM8nebXd3jHQZn+SM0leSfLQQP2BJC+1x55MkpvztiRJw4wy0r8C/EpV/RCwDdibZAuwDzhRVZuBE+0+7bGdwL3AduCpJKvacx0E9gCb27J9Ed+LJGke84Z+VZ2rqi+19UvAaWAdsAM43DY7DDzc1ncAR6vqclW9BpwBtiZZC6yuqpNVVcCRgTaSpDFY0Jx+kk3AB4EvAGuq6hzM/GEA7m6brQPeHGg23Wrr2vrs+rDX2ZNkKsnUxYsXF9JFSdIcRg79JN8D/A7wy1X1rbk2HVKrOerXFqsOVdVkVU1OTEyM2kVJ0jxGuvZOkvcyE/ifqKpPtfL5JGur6lyburnQ6tPAhoHm64Gzrb5+SF36Dq+1I91coxy9E+BjwOmq+rWBh44Du9r6LuDZgfrOJLcluYeZD2xfaFNAl5Jsa8/56EAbSdIYjDLS/xDwC8BLSb7cav8GeAI4lmQ38AbwCEBVnUpyDHiZmSN/9lbV1dbuMeAZ4HbgubZImsfs/4C81LJu1LyhX1V/yPD5eIAHr9PmAHBgSH0KuG8hHZQkLR7PyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6ohfjK4l5wlZ0vg40pekjhj6ktQRp3ekFWhwSsyzc7UQjvQlqSOGviR1xNCXpI4Y+pLUEUNfkjri0TtaEp6QJS0NR/qS1BFDX5I64vSOtMJ5opYWwpG+JHVk3pF+ko8DPw1cqKr7Wu1O4LeATcDrwM9W1TfaY/uB3cBV4KNV9dlWf4B3vhT9M8DjVVWL+3a0nPnhrbT0RhnpPwNsn1XbB5yoqs3AiXafJFuAncC9rc1TSVa1NgeBPcDmtsx+TknSTTZv6FfVHwB/Oau8Azjc1g8DDw/Uj1bV5ap6DTgDbE2yFlhdVSfb6P7IQBtJ0pjc6Jz+mqo6B9Bu7271dcCbA9tNt9q6tj67PlSSPUmmkkxdvHjxBrsoSZptsT/IzZBazVEfqqoOVdVkVU1OTEwsWuckqXc3Gvrn25QN7fZCq08DGwa2Ww+cbfX1Q+qSpDG60dA/Duxq67uAZwfqO5PcluQeZj6wfaFNAV1Ksi1JgEcH2kiSxmSUQzY/CfwT4K4k08C/A54AjiXZDbwBPAJQVaeSHANeBq4Ae6vqanuqx3jnkM3n2qJbnIdpSstLlvuh8pOTkzU1NbXU3dANMvSXjmfn9i3Ji1U1ObvuGbmS1BFDX5I64gXXtOic0pGWL0f6ktQRQ1+SOmLoS1JHnNOXblF+uYqGMfS1KPzwVloZnN6RpI4Y+pLUEad3dMOc0lk5nN/X2xzpS1JHHOlrQRzdSyuboS91xqmevhn6mpeje+nW4Zy+JHXEkb7UMad6+mPoayindKRbk6Gv7zDo++aovw/O6UtSR8Y+0k+yHfh1YBXwdFU9Me4+9M4RveZzvZ8R/wNY+cYa+klWAb8B/CQwDXwxyfGqenmc/eiF4a7F5h+DlW/cI/2twJmq+jpAkqPADsDQvw6DWyvBYv2c+sfj5ht36K8D3hy4Pw38g9kbJdkD7Gl3/yrJK2Po213AX4zhdVYy99Hc3D/zm3Mf5T+OsSfL12L9HP29YcVxh36G1OqaQtUh4NDN7847kkxV1eQ4X3OlcR/Nzf0zP/fR/G72Phr30TvTwIaB++uBs2PugyR1a9yh/0Vgc5J7krwP2AkcH3MfJKlbY53eqaorSf4l8FlmDtn8eFWdGmcf5jDW6aQVyn00N/fP/NxH87up+yhV10ypS5JuUZ6RK0kdMfQlqSPdhn6SO5M8n+TVdnvHkG02JPn9JKeTnEry+FL0damMso/adh9PciHJn4y7j0shyfYkryQ5k2TfkMeT5Mn2+FeS/MhS9HMpjbCPfjDJySSXk/yrpejjUhthH/18+/n5SpI/SvKBxXjdbkMf2AecqKrNwIl2f7YrwK9U1Q8B24C9SbaMsY9LbZR9BPAMsH1cnVpKA5cS+TCwBfi5IT8THwY2t2UPcHCsnVxiI+6jvwQ+CvynMXdvWRhxH70G/OOq+mHgP7BIH/D2HPo7gMNt/TDw8OwNqupcVX2prV8CTjNzVnEv5t1HAFX1B8z8EvfgO5cSqaq/Ad6+lMigHcCRmvF54P1J1o67o0to3n1UVReq6ovAt5eig8vAKPvoj6rqG+3u55k5r+ld6zn011TVOZgJd+DuuTZOsgn4IPCFm9+1ZWNB+6gTwy4lMnsgMMo2t7Le3/8oFrqPdgPPLcYL39JfopLkfwLfN+ShX13g83wP8DvAL1fVtxajb8vFYu2jjoxyKZGRLjdyC+v9/Y9i5H2U5MeYCf0fXYwXvqVDv6p+4nqPJTmfZG1VnWv/el+4znbvZSbwP1FVn7pJXV0yi7GPOjPKpUR6v9xI7+9/FCPtoyQ/DDwNfLiq3lqMF+55euc4sKut7wKenb1BkgAfA05X1a+NsW/Lxbz7qEOjXErkOPBoO4pnG/B/3p4m64SXW5nfvPsoyUbgU8AvVNWfLtorV1WXC/C9zByR8mq7vbPV/y7wmbb+o8z8y/UV4Mtt+aml7vty2kft/ieBc8x8KDcN7F7qvt/k/fJTwJ8CXwN+tdV+EfjFth5mjsz4GvASMLnUfV6G++j72s/Kt4BvtvXVS93vZbaPnga+MZA9U4vxul6GQZI60vP0jiR1x9CXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHfn/m6mWP00jyLUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data=dataset(LPFe_Map,LPK_Map,LPTh_Map,LPTi_Map,albedo,360,720)\n",
    "test_loader=DataLoader(test_data,batch_size=1)\n",
    "loss_function=torch.nn.MSELoss()\n",
    "net_test=model(4,10,1)\n",
    "net_test=net_test.eval().cuda()\n",
    "net_test.load_state_dict(torch.load(\"/home/gokul/g0kul6/ml4sci/Albedo_Task_ML4SCi/albedo_200_1e-05.pth\"))\n",
    "right_predicted=[]\n",
    "right_truth=np.array(pd.read_csv(albedo))[:,360:720]\n",
    "total_loss=[]\n",
    "for i,l in test_loader:\n",
    "    i=i.cuda()\n",
    "    l=l.cuda()\n",
    "    l=torch.reshape(l,(len(l),1))\n",
    "    output=net_test(i)\n",
    "    loss=loss_function(output,l)\n",
    "    loss=loss.cpu().item()\n",
    "    total_loss.append(np.sqrt(loss))\n",
    "    right_predicted.append(output.cpu().item())\n",
    "print(\"RMSE Loss on right half :\",np.mean(total_loss))\n",
    "right_predicted=np.reshape(right_predicted,(359,360))\n",
    "residual=right_predicted-right_truth\n",
    "plt.hist(residual.flatten(),bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
